{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "# Step 1: Download the desired Python version based on the OS\n",
    "if platform.system() == \"Windows\":\n",
    "    !curl -O https://www.python.org/ftp/python/3.7.9/python-3.7.9-amd64.exe\n",
    "    # Step 2: Install the downloaded Python version silently\n",
    "    !start /wait python-3.7.9-amd64.exe /quiet InstallAllUsers=1 PrependPath=1\n",
    "    \n",
    "    # Find the short path for the installed Python executable\n",
    "    short_path = subprocess.check_output('for %I in (\"C:\\\\Program Files\\\\Python37\\\\python.exe\") do @echo %~sI', shell=True).decode().strip()\n",
    "    print(f\"Short path for Python: {short_path}\")\n",
    "\n",
    "    # Step 3: Create a new virtual environment using the newly installed Python version\n",
    "    !{short_path} -m venv myenv\n",
    "\n",
    "    # Step 4: Activate the virtual environment and install Jupyter and ipykernel\n",
    "    !myenv\\Scripts\\activate && pip install jupyter ipykernel\n",
    "\n",
    "    # Step 5: Create a new kernel for Jupyter using the virtual environment\n",
    "    !myenv\\Scripts\\activate && python -m ipykernel install --user --name myenv --display-name \"Python 3.7.9\"\n",
    "    \n",
    "elif platform.system() == \"Darwin\":  # macOS\n",
    "    # NICHT GETESTET\n",
    "    !curl -O https://www.python.org/ftp/python/3.7.9/python-3.7.9-macosx10.9.pkg\n",
    "    # Step 2: Install the downloaded Python version silently\n",
    "    !sudo installer -pkg python-3.7.9-macosx10.9.pkg -target /\n",
    "    \n",
    "    python_path = \"/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7\"\n",
    "\n",
    "    # Step 3: Create a new virtual environment using the newly installed Python version\n",
    "    !{python_path} -m venv myenv\n",
    "\n",
    "    # Step 4: Activate the virtual environment and install Jupyter and ipykernel\n",
    "    !source myenv/bin/activate && pip install jupyter ipykernel\n",
    "\n",
    "    # Step 5: Create a new kernel for Jupyter using the virtual environment\n",
    "    !source myenv/bin/activate && python -m ipykernel install --user --name myenv --display-name \"Python 3.7.9\"\n",
    "    \n",
    "elif platform.system() == \"Linux\":\n",
    "    # NICHT GETESTET\n",
    "    !curl -O https://www.python.org/ftp/python/3.7.9/Python-3.7.9.tgz\n",
    "    !tar -xzf Python-3.7.9.tgz\n",
    "    os.chdir('Python-3.7.9')\n",
    "    !./configure\n",
    "    !make\n",
    "    !sudo make install\n",
    "\n",
    "    python_path = \"/usr/local/bin/python3.7\"\n",
    "\n",
    "    # Step 3: Create a new virtual environment using the newly installed Python version\n",
    "    !{python_path} -m venv myenv\n",
    "\n",
    "    # Step 4: Activate the virtual environment and install Jupyter and ipykernel\n",
    "    !source myenv/bin/activate && pip install jupyter ipykernel\n",
    "\n",
    "    # Step 5: Create a new kernel for Jupyter using the virtual environment\n",
    "    !source myenv/bin/activate && python -m ipykernel install --user --name myenv --display-name \"Python 3.7.9\"\n",
    "\n",
    "# Inform the user\n",
    "print(\"Kernel installation complete. Restart the Jupyter kernel and select 'Python 3.7.9' to use the new environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "# Hier erwarten wir jetzt 3.7.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation der benötigten Bibliotheken direkt über Jupyter, ist weniger umständlich und landet direkt in der richtigen Umgebung\n",
    "# Bedigung ist, dass Python 3.7.9 installiert ist, sonst schlägt die Installation fehl\n",
    "# python -m pip install pip==20.1.1\n",
    "!pip install absl-py==2.1.0\n",
    "!pip install astor==0.8.1\n",
    "!pip install backcall==0.2.0\n",
    "!pip install colorama==0.4.6\n",
    "!pip install cycler==0.11.0\n",
    "!pip install debugpy==1.7.0\n",
    "!pip install decorator==5.1.1\n",
    "!pip install entrypoints==0.4\n",
    "!pip install fonttools==4.38.0\n",
    "!pip install gast==0.2.2\n",
    "!pip install gdown==4.7.3\n",
    "!pip install google-pasta==0.2.0\n",
    "!pip install grpcio==1.62.2\n",
    "!pip install h5py==2.10.0\n",
    "!pip install importlib-metadata==6.7.0\n",
    "!pip install ipykernel==6.16.2\n",
    "!pip install ipython==7.34.0\n",
    "!pip install jedi==0.19.1\n",
    "!pip install jupyter-client==7.4.9\n",
    "!pip install jupyter-core==4.12.0\n",
    "!pip install Keras==2.3.1\n",
    "!pip install Keras-Applications==1.0.8\n",
    "!pip install Keras-Preprocessing==1.1.0\n",
    "!pip install kiwisolver==1.4.5\n",
    "!pip install Markdown==3.4.4\n",
    "!pip install MarkupSafe==2.1.5\n",
    "!pip install matplotlib==3.5.3\n",
    "!pip install matplotlib-inline==0.1.6\n",
    "!pip install nest-asyncio==1.6.0\n",
    "!pip install numpy==1.21.6\n",
    "!pip install opencv-contrib-python==4.1.2.30\n",
    "!pip install opt-einsum==3.3.0\n",
    "!pip install packaging==24.0\n",
    "!pip install parso==0.8.4\n",
    "!pip install pickleshare==0.7.5\n",
    "!pip install Pillow==9.5.0\n",
    "!pip install prompt-toolkit==3.0.47\n",
    "!pip install protobuf==3.20.0\n",
    "!pip install psutil==5.9.8\n",
    "!pip install pygments==2.17.2\n",
    "!pip install pyparsing==3.1.2\n",
    "!pip install python-dateutil==2.9.0.post0\n",
    "!pip install pywin32==306\n",
    "!pip install PyYAML==6.0.1\n",
    "!pip install pyzmq==26.0.3\n",
    "!pip install scipy==1.7.3\n",
    "!pip install six==1.16.0\n",
    "!pip install tensorboard==1.15.0\n",
    "!pip install tensorflow==1.15.0\n",
    "!pip install tensorflow-estimator==1.15.1\n",
    "!pip install termcolor==2.3.0\n",
    "!pip install tornado==6.2\n",
    "!pip install tqdm==4.41.1\n",
    "!pip install traitlets==5.9.0\n",
    "!pip install typing-extensions==4.7.1\n",
    "!pip install wcwidth==0.2.13\n",
    "!pip install Werkzeug==2.2.3\n",
    "!pip install wrapt==1.16.0\n",
    "!pip install zipp==3.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1o_PM_zB6FxJRdLpEx8lEAhL29IMe1KzI\n",
      "From (redirected): https://drive.google.com/uc?id=1o_PM_zB6FxJRdLpEx8lEAhL29IMe1KzI&confirm=t&uuid=352fc8ca-7539-4cae-8f2d-01b2368e7df9\n",
      "To: c:\\Users\\Tobias\\Downloads\\keras-yolo3-master\\models\\backend.h5\n",
      " 34%|███▍      | 84.9M/249M [00:32<01:21, 2.00MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7312\\2370939199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'https://drive.google.com/uc?id=1o_PM_zB6FxJRdLpEx8lEAhL29IMe1KzI'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'models/backend.h5'\u001b[0m  \u001b[1;31m# Specify the desired output file name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gdown\\download.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mt_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"stream\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    877\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                 \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# StringIO doesn't like amt=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m     def _raw_read(\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python37\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 84.9M/249M [00:50<01:21, 2.00MB/s]"
     ]
    }
   ],
   "source": [
    "# Herunterladen der Modelle\n",
    "import gdown\n",
    "gdown.download('https://drive.google.com/uc?id=1o_PM_zB6FxJRdLpEx8lEAhL29IMe1KzI', 'models/backend.h5', quiet=False)\n",
    "gdown.download('https://drive.google.com/uc?id=1kaB6H0CqrzwDPtWedOqYVrVQ5hW36Bno', 'models/raccoon_pre_trained.h5', quiet=False)\n",
    "gdown.download('https://drive.google.com/uc?id=1NGMJ1d49AaI3rspJsgkDjgYLFiUlPCTX', 'models/voc.h5', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import create_training_instances, create_callbacks\n",
    "from yolo import create_yolov3_model, dummy_loss, _conv_block, YoloLayer, Convolution, Residual, AvgPool, Connected, Softmax\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate, makedirs\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, Input, UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "###############################\n",
    "#   Erstellen des Modells\n",
    "###############################  \n",
    "\n",
    "def create_yolov3_model(nb_class, anchors, max_box_per_image,  max_grid, batch_size, warmup_batches, ignore_thresh, grid_scales, obj_scale, noobj_scale, xywh_scale, class_scale):\n",
    "    input_image = Input(shape=(None, None, 3)) # net_h, net_w, 3\n",
    "    true_boxes  = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
    "    true_yolo_1 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n",
    "    true_yolo_2 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n",
    "    true_yolo_3 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n",
    "\n",
    "    x = input_image\n",
    "\n",
    "    ###############################\n",
    "    #   BEGINN OF DARKNET-53 BACKBONE LAYERS\n",
    "    ###############################  \n",
    "\n",
    "    x = Convolution(inp=x, layer_index=0, filter=32, kernel=3, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=1, filter=64, kernel=3, stride=2)\n",
    "    x = Convolution(inp=x, layer_index=2, filter=32, kernel=1, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=3, filter=64, kernel=3, stride=1)\n",
    "    x = Residual(inp=x, layer_index=4)\n",
    "\n",
    "    x = Convolution(inp=x, layer_index=5, filter=128, kernel=3, stride=2)\n",
    "\n",
    "    for i in range(2):\n",
    "        x = Convolution(inp=x, layer_index=6+i*3, filter=64, kernel=1, stride=1)\n",
    "        x = Convolution(inp=x, layer_index=7+i*3, filter=128, kernel=3, stride=1)\n",
    "        x = Residual(inp=x, layer_index=8+i*3)\n",
    "    \n",
    "    # Layer 12 fehlt\n",
    "    #x = \n",
    "\n",
    "    for i in range(8):\n",
    "        x = Convolution(inp=x, layer_index=13+i*3, filter=128, kernel=1, stride=1)\n",
    "        x = Convolution(inp=x, layer_index=14+i*3, filter=256, kernel=3, stride=1)\n",
    "        x = Residual(inp=x, layer_index=15+i*3)\n",
    "        \n",
    "    skip_36 = x\n",
    "\n",
    "    x = Convolution(inp=x, layer_index=37, filter=512, kernel=3, stride=2)\n",
    "\n",
    "    for i in range(8):\n",
    "        x = Convolution(inp=x, layer_index=38+i*3, filter=256, kernel=1, stride=1)\n",
    "        # Hier fehlt auch eine Layer\n",
    "        #x = \n",
    "        x = Residual(inp=x, layer_index=40+i*3)\n",
    "        \n",
    "    # Was könnte hier zu beachten sein? Gibt es Parallelen zu Layer 36?\n",
    "    skip_61 = x\n",
    "\n",
    "    x = Convolution(inp=x, layer_index=62, filter=1024, kernel=3, stride=2)\n",
    "\n",
    "    for i in range(4):\n",
    "        x = Convolution(inp=x, layer_index=63+i*3, filter=512, kernel=1, stride=1)\n",
    "        x = Convolution(inp=x, layer_index=64+i*3, filter=1024, kernel=3, stride=1)\n",
    "        x = Residual(inp=x, layer_index=65+i*3)\n",
    "        \n",
    "    ###############################\n",
    "    #   END OF DARKNET-53 BACKBONE LAYERS\n",
    "    ############################### \n",
    "\n",
    "    ###############################\n",
    "    #   BEGIN OF YOLO-SPECIFIC LAYERS\n",
    "    ############################### \n",
    "\n",
    "    # Layer 80 => 82\n",
    "    x = Convolution(inp=x, layer_index=75, filter=512, kernel=1, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=76, filter=1024, kernel=3, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=77, filter=512, kernel=1, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=78, filter=1024, kernel=3, stride=1)\n",
    "    x = Convolution(inp=x, layer_index=79, filter=512, kernel=1, stride=1)\n",
    "\n",
    "    pred_yolo_1 = Convolution(inp=x, layer_index=80, filter=1024, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_1 = Convolution(inp=pred_yolo_1, layer_index=81, filter=(3*(5+nb_class)), kernel=1, stride=1, bnorm=False, leaky=False)\n",
    "    loss_yolo_1 = YoloLayer(anchors[12:],  [1*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[0], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = Convolution(inp=x, layer_index=84, filter=256, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = Convolution(inp=x, layer_index=87, filter=256, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    x = Convolution(inp=x, layer_index=88, filter=512, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    x = Convolution(inp=x, layer_index=89, filter=256, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    x = Convolution(inp=x, layer_index=90, filter=512, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    x = Convolution(inp=x, layer_index=91, filter=256, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    pred_yolo_2 = Convolution(inp=x, layer_index=92, filter=512, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_2 = Convolution(inp=pred_yolo_2, layer_index=93, filter=(3*(5+nb_class)), kernel=1, stride=1, bnorm=False, leaky=False)\n",
    "    loss_yolo_2 = YoloLayer(anchors[6:12], [2*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[1], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_2, true_yolo_2, true_boxes])\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = Convolution(inp=x, layer_index=96, filter=128, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    pred_yolo_3 = Convolution(inp=x, layer_index=99, filter=128, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=100, filter=256, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=101, filter=128, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=102, filter=256, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=103, filter=128, kernel=1, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=104, filter=256, kernel=3, stride=1, bnorm=True, leaky=True)\n",
    "    pred_yolo_3 = Convolution(inp=pred_yolo_3, layer_index=105, filter=(3*(5+nb_class)), kernel=1, stride=1, bnorm=False, leaky=False)\n",
    "    loss_yolo_3 = YoloLayer(anchors[:6], [4*num for num in max_grid], batch_size, warmup_batches, ignore_thresh, grid_scales[2], obj_scale, noobj_scale, xywh_scale, class_scale)([input_image, pred_yolo_3, true_yolo_3, true_boxes]) \n",
    "\n",
    "    train_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\n",
    "    infer_model = Model(input_image, [pred_yolo_1, pred_yolo_2, pred_yolo_3])\n",
    "\n",
    "    return [train_model, infer_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00) # Kernel schließen um Ressourcen frei zu geben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import create_training_instances, create_callbacks\n",
    "from yolo import dummy_loss, _conv_block, create_yolov3_model, YoloLayer, Convolution, Residual, AvgPool, Connected, Softmax\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "###############################\n",
    "#   Start des Trainings.\n",
    "#   Die Annotations müssen dafür schon abgelegt sein!\n",
    "###############################\n",
    "\n",
    "###############################\n",
    "#   Parse the annotations \n",
    "###############################\n",
    "train_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n",
    "    \"./raccoon_dataset/annotations/\",\n",
    "    \"./raccoon_dataset/images/\",\n",
    "    \"x.pkl\",\n",
    "    \"./raccoon_dataset/annotations_validation/\",\n",
    "    \"./raccoon_dataset/images_validation/\",\n",
    "    \"x.pkl\",\n",
    "    ['raccoon']\n",
    ")\n",
    "labels = ['raccoon']\n",
    "anchors = [17,18, 28,24, 36,34, 42,44, 56,51, 72,66, 90,95, 92,154, 139,281]\n",
    "train_times = 1 #1\n",
    "batch_size = 1 #3\n",
    "epochs = 1 #2\n",
    "warm_up_epochs = 1 #1\n",
    "warmup_batches = 1 #2\n",
    "learning_rate = 1e-4 #1e-4\n",
    "\n",
    "###############################\n",
    "#   Create the generators \n",
    "###############################    \n",
    "train_generator = BatchGenerator(\n",
    "    instances           = train_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size,\n",
    "    min_net_size        = 288,\n",
    "    max_net_size        = 448,\n",
    "    shuffle             = True, \n",
    "    jitter              = 0.3, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "valid_generator = BatchGenerator(\n",
    "    instances           = valid_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size,\n",
    "    min_net_size        = 288,\n",
    "    max_net_size        = 448,   \n",
    "    shuffle             = True, \n",
    "    jitter              = 0.0, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "###############################\n",
    "#   Create the model \n",
    "###############################\n",
    "\n",
    "train_model, infer_model = create_yolov3_model(\n",
    "    nb_class            = len(labels), \n",
    "    anchors             = anchors,\n",
    "    max_box_per_image   = max_box_per_image, \n",
    "    max_grid            = [488, 488], \n",
    "    batch_size          = batch_size,\n",
    "    warmup_batches      = warmup_batches,\n",
    "    ignore_thresh       = 0.5,\n",
    "    grid_scales         = [1,1,1],\n",
    "    obj_scale           = 5,\n",
    "    noobj_scale         = 1,\n",
    "    xywh_scale          = 1,\n",
    "    class_scale         = 1 \n",
    ")\n",
    "\n",
    "# load the backend weight only\n",
    "train_model.load_weights(\"models/backend.h5\", by_name=True)     \n",
    "\n",
    "optimizer = Adam(lr=learning_rate, clipnorm=0.001)\n",
    "train_model.compile(loss=dummy_loss, optimizer=optimizer)      \n",
    "\n",
    "###############################\n",
    "#   Kick off the training\n",
    "###############################\n",
    "callbacks = create_callbacks('models/raccoon_self_trained.h5', 'log', infer_model)\n",
    "\n",
    "train_model.fit_generator(\n",
    "    generator        = train_generator, \n",
    "    steps_per_epoch  = len(train_generator) * train_times, \n",
    "    epochs           = epochs + warm_up_epochs, \n",
    "    verbose          = 2,\n",
    "    callbacks        = callbacks, \n",
    "    workers          = 4,\n",
    "    max_queue_size   = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00) # Kernel schließen um Ressourcen frei zu geben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#   Predict bounding boxes\n",
    "###############################  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "###############################\n",
    "#   Set some parameter\n",
    "###############################       \n",
    "net_h, net_w = 416, 416 # a multiple of 32, the smaller the faster\n",
    "obj_thresh = 0.5\n",
    "\n",
    "# Für das selbst trainierte Model nehmen wir ~0.00001, da das Modell bei unausreichendem Training sonst zu viele Bounding Boxes ausgibt\n",
    "# Für das vortrainierte Moddell 0.45\n",
    "nms_thresh = 0.45\n",
    "\n",
    "###############################\n",
    "#   Load the model\n",
    "###############################\n",
    "infer_model = load_model('models/raccoon_self_trained.h5')\n",
    "\n",
    "# raccoon 1 - 5\n",
    "image = cv2.imread('./raccoon_dataset/images/raccoon-1.jpg')\n",
    "\n",
    "# predict the bounding boxes\n",
    "anchors = [17,18, 28,24, 36,34, 42,44, 56,51, 72,66, 90,95, 92,154, 139,281]\n",
    "boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, anchors, obj_thresh, nms_thresh)[0]\n",
    "\n",
    "# draw bounding boxes on the image using labels\n",
    "draw_boxes(image, boxes, ['raccoon'], obj_thresh) \n",
    "\n",
    "# write the image with bounding boxes to file and show in jupyter\n",
    "cv2.imwrite('racc_detect.jpg', np.uint8(image))    \n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00) # Kernel schließen um Ressourcen frei zu geben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#   Evaluation of the model\n",
    "###############################\n",
    "\n",
    "from voc import parse_voc_annotation\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate\n",
    "from keras.models import load_model\n",
    "\n",
    "###############################\n",
    "#   Create the validation generator\n",
    "###############################  \n",
    "valid_ints, labels = parse_voc_annotation(\n",
    "    \"./raccoon_dataset/annotations_validation\", \n",
    "    \"./raccoon_dataset/images_validation\", \n",
    "    \"x.pkl\",\n",
    "    ['raccoon']\n",
    ")\n",
    "labels = ['raccoon']\n",
    "\n",
    "\n",
    "anchors = [17,18, 28,24, 36,34, 42,44, 56,51, 72,66, 90,95, 92,154, 139,281]\n",
    "valid_generator = BatchGenerator(\n",
    "    instances           = valid_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = 0,\n",
    "    batch_size          = 32,\n",
    "    min_net_size        = 288,\n",
    "    max_net_size        = 448,   \n",
    "    shuffle             = True, \n",
    "    jitter              = 0.0, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "###############################\n",
    "#   Load the model and do evaluation\n",
    "###############################\n",
    "infer_model = load_model('models/raccoon_self_trained.h5')\n",
    "\n",
    "# compute mAP for all the classes\n",
    "average_precisions = evaluate(infer_model, valid_generator)\n",
    "\n",
    "# print the score\n",
    "for label, average_precision in average_precisions.items():\n",
    "    print(labels[label] + ': {:.4f}'.format(average_precision))\n",
    "print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#   Live video Demo\n",
    "###############################   \n",
    "\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "\n",
    "###############################\n",
    "#   Set some parameter\n",
    "###############################       \n",
    "net_h, net_w = 160, 160 # a multiple of 32, the smaller the faster, standard: 416x416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "\n",
    "###############################\n",
    "#   Load the model\n",
    "###############################\n",
    "infer_model = load_model('models/voc.h5')\n",
    "\n",
    "video_reader = cv2.VideoCapture(0)\n",
    "\n",
    "# the main loop\n",
    "batch_size  = 1\n",
    "images      = []\n",
    "anchors = [17,18, 28,24, 36,34, 42,44, 56,51, 72,66, 90,95, 92,154, 139,281]\n",
    "labels = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "while True:\n",
    "    ret_val, image = video_reader.read()\n",
    "    if ret_val == True: images += [image]\n",
    "\n",
    "    if (len(images)==batch_size) or (ret_val==False and len(images)>0):\n",
    "        batch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, anchors, obj_thresh, nms_thresh)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            draw_boxes(images[i], batch_boxes[i], labels, obj_thresh) \n",
    "            cv2.imshow('video with bboxes', images[i])\n",
    "        images = []\n",
    "    if cv2.waitKey(1) == 27: \n",
    "        break  # esc to quit\n",
    "cv2.destroyAllWindows()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
